<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">

    <title>Apache Spark 2.0 Workshop - The Elements of Apache Spark</title>

    <meta name="description" content="The Basics of Apache Spark">
    <meta name="author" content="Jacek Laskowski">

    <meta name="apple-mobile-web-app-capable" content="yes" />
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

    <link rel="stylesheet" href="css/reveal.css">
    <link rel="stylesheet" href="css/theme/beige.css" id="theme">

    <!-- Code syntax highlighting -->
    <link rel="stylesheet" href="lib/css/zenburn.css">

    <!-- Printing and PDF exports -->
    <script>
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

    <!-- https://github.com/hakimel/reveal.js/issues/174 -->
    <style>
      .slides .header {
        position: absolute;
        top: 0px;
        right: 0px;
      }
      .slides .footer {
        position: absolute;
        bottom: 0px;
        left: 15%;
      }
    </style>
    <!--[if lt IE 9]>
    <script src="lib/js/html5shiv.js"></script>
    <![endif]-->
  </head>

  <body>
    <div class="reveal">

      <div class="slides">
        <div class="footer">
          <small>Copyright ©2016 Jacek Laskowski &amp; Value Amplify Consulting Group</small>
        </div>

        <section class="intro" data-transition="zoom">
          <p>
            <img width="15%" style="background:none; border:none; box-shadow:none;" data-src="images/spark-logo.png">
            <img width="30%" src="images/ValueAmplify_Logo_Final_medium.jpg" style="border: 0">
          </p>
          <h1>The Elements of</h1>
          <h1>Apache Spark 2.0</h1>
          <h3>Large-Scale Big Data Analytics</h3>
          <h4><a href="https://blog.jaceklaskowski.pl">Jacek Laskowski</a> / <a href="https://twitter.com/jaceklaskowski">@jaceklaskowski</a> / <a href="https://github.com/jaceklaskowski">GitHub</a> / <a href="http://bit.ly/mastering-apache-spark">Mastering Apache Spark Notes</a></h4>
        </section>

        <section>
          <section id="modules-day1">
            <h2>Modules - Day 1 (1 of 2)</h2>
            <ul>
              <li>The Elements of Apache Spark (<i>aka</i> Why Spark)</li>
              <li>Tools Intro - IntelliJ IDEA and Scala Worksheet</li>
              <li>Introduction to Scala (<i>aka</i> Why Scala)</li>
              <li>Spark Setup and Your First Spark Application</li>
              <li><b>Exercise</b>: My First Scala Application (using IntelliJ IDEA)</li>
            </ul>
          </section>
          <section>
            <h2>Modules - Day 1 (2 of 2)</h2>
            <ul>
              <li>Introduction to sbt and sbt-assembly</li>
              <li><b>Exercise</b>: Running Scala Application from Command Line</li>
              <li>Introduction to Spark SQL using spark-shell and Spark's web U</li>
              <li><b>Exercise</b>: My First Spark SQL Application (using IntelliJ IDEA)</li>
              <li>Introduction to spark-submit and run-example</li>
              <li><b>Exercise</b>: spark-submit Your Spark App / run-example SparkPi</li>
            </ul>
          </section>
        </section>

        <section>
          <h1>Apache Spark 2.0</h1>
        </section>

        <section>
          <img width="65%" style="background:none; border:none; box-shadow:none;" data-src="images/about-spark.png" />
          <small>From <a href="http://spark.apache.org/">the official documentation of Apache Spark</a></small>
        </section>

        <section>
          <p>
            <img width="100%" src="images/spark-platform.png" style="border: 0">
          </p>
        </section>

        <section>
          <h2>Why Apache Spark 2.0</h2>
          <section id="why-spark">
            <p>"Apache Spark is a fast and general-purpose cluster computing system."</p>
            <p>
              <small><a href="http://spark.apache.org/docs/latest/index.html">http://spark.apache.org/docs/latest/index.html</a></small>
            </p>
          </section>

          <section>
            <p>
              "Apache Spark is an open-source distributed general-purpose cluster computing framework with in-memory data processing engine"
            </p>
            <p>
              <small><a href="https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-overview.html">https://jaceklaskowski.gitbooks.io/mastering-apache-spark/content/spark-overview.html</a></small>
            </p>
          </section>
          <section>
            <p>
              "One of the Spark project goals was to deliver a platform that supports a very wide array of <b>diverse workflows</b> - not only MapReduce <b>batch jobs</b> (there were available in Hadoop already at that time), but also <b>iterative computations</b> like graph algorithms or Machine Learning. [...] And also <b>different scales of workloads</b> from sub-second interactive jobs to jobs that run for many hours."
            </p>
            <p>
              <small><a href="https://youtu.be/49Hr5xZyTEA">Matei Zaharia - the author of Apache Spark - in Introduction to AmpLab Spark Internals video</a></small>
            </p>
          </section>
          <section>
            High-level APIs for Scala, Java, Python, R and SQL languages
          </section>
          <section>
            <b>RDD</b> - Resilient Distributed Dataset
            <p>
              (or simply a Distributed Parallel Collection API for Scala)
            </p>
          </section>
          <section>
            <b>Spark SQL</b> for processing structured and semi-structured datasets
          </section>
          <section>
            Support for good ol' <b>SQL</b>
          </section>
          <section>
            <b>DataFrame</b> - Python's pandas for Distributed Environment
          </section>
          <section>
            <b>Dataset</b> for Type-Safe DataFrames
          </section>
          <section>
            Interactive Exploration / Exploratory Analytics
            <p>
              (ad hoc queries)
            </p>
          </section>
          <section>
            Batch and Iterative Workloads
          </section>
          <section>
            Rich Data Source Support
          </section>
          <section>
            Cluster Deployment with built-in <b>Spark Standalone</b>, <b>Hadoop YARN</b>, and <b>Apache Mesos</b>
          </section>
          <section>
            Data Locality
          </section>
          <section>
            <b>Spark MLlib</b> for Machine Learning in Distributed Environment with Peta Bytes of Data
          </section>
          <section>
            <b>Spark Streaming</b> for Scalable, High-tThroughput, Fault-Tolerant Stream Processing of Live Data Streams
          </section>
          <section>
            <b>Spark GraphX</b> for Graphs and Graph-Parallel Computation
          </section>
        </section>

        <section id="spark-project">
          <p>
            <img width="100%" src="images/spark-platform.png" style="border: 0">
          </p>
        </section>

        <section>
          <h2>Spark Core</h2>
          <section id="spark-core">
            <ul>
              <li><b>RDD</b> is the main abstraction of Apache Spark</li>
              <li>
                <b>R</b>esilient
              </li>
              <li>
                <b>D</b>istributed
              </li>
              <li>
                <b>D</b>ataset
              </li>
              <li>
                In-Memory, Immutable, Lazy Evaluated, Partitioned, Cacheable, Parallel, Typed
              </li>
              <li>
                <b>CAUTION:</b> Often too low-level these days. Leave it alone until you really want it.
              </li>
            </ul>
          </section>
          <section>
            <h2>Partitions</h2>
            <ol>
              <li>
                <b>Partitions</b> are logical buckets for data.
              </li>
              <li>
                Partitions correspond to Hadoop's splits (if the data lives on HDFS) or partitioning schemes in the source storage
              </li>
              <li>
                RDD (and hence the data inside) is partitioned.
              </li>
              <li>
                Spark manages data using partitions that helps parallelize distributed data processing with minimal network traffic for sending data between executors.
              </li>
              <li>
                Data in partitions can be <b>skewed</b>, i.e. unevenly distributed across partitions.
              </li>
            </ol>
          </section>
          <section>
            <p>
              <img width="100%" src="images/spark-rdd-partitioned-distributed.png" style="border: 0">
            </p>
          </section>
          <section>
            <h2>Shuffle</h2>
            <ol>
              <li>
                <b>Shuffle</b> is Spark’s mechanism for re-distributing data so that it’s grouped differently across partitions.
              </li>
              <li>
                Data is often distributed unevenly across partitions.
              </li>
              <li>
                <b>repartition</b> and <b>coalesce</b> operators can repartition a dataset.
              </li>
            </ol>
          </section>
          <section>
            <h2>DAGScheduler</h2>
            <img width="60%" src="images/dagscheduler-rdd-partitions-job-resultstage.png" style="border: 0">
          </section>
          <section>
            <h2>Jobs</h2>
            <img width="70%" src="images/rdd-job-partitions.png" style="border: 0">
          </section>
          <section>
            <h2>Stages</h2>
            <img width="70%" src="images/dagscheduler-stages.png" style="border: 0">
          </section>
          <section>
            <h2>Tasks</h2>
            <img width="100%" src="images/stage-tasks.png" style="border: 0">
          </section>
        </section>

        <section id="spark-sql">
          <h2>Spark SQL</h2>
          <ul>
            <li>
              Distributed SQL Engine for Structured Data Processing
            </li>
            <li>
              <b>SQL</b> Interface
            </li>
            <li><b>Dataset</b> and <b>DataFrame</b></li>
            <ul>
              <li>
                DataFrame is a type alias for Dataset of Rows.
              </li>
            </ul>
            <li>
              Query DSL
            </li>
            <li>
              Hive Support
            </li>
            <li>
              <b>UDF</b> - User-Defined Functions
            </li>
            <li>
              Aggregation and Window Operators
            </li>
          </ul>
        </section>

        <section id="spark-mllib">
          <h2>Spark MLlib</h2>
          <ul>
            <li>
              Large-Scale Distributed Machine Learning
            </li>
            <li>
              "Making practical machine learning scalable and easy"
            </li>
            <li>
               DataFrame-based API
            </li>
            <li><b>Pipeline API</b> for designing, evaluating, and tuning machine learning pipelines</li>
            <li>Classification, Regression, Clustering, Recommendation, Collaborative Filtering, ...</li>
            <li>
              Model Import / Export
            </li>
          </ul>
        </section>

        <section>
          <section id="spark-streaming">
            <h2>Spark Streaming</h2>
            <ol>
              <li>
                Scalable, high-throughput, fault-tolerant stream processing of live<small>*</small> data streams
                <ul>
                  <li>
                    Works in batches.
                  </li>
                </ul>
              </li>
              <li><b>Discretized Stream</b> (DStream)</li>
              <li>
                Continuous Data Stream
              </li>
              <li>
                Tight integration with other Spark modules
              </li>
            </ol>
          </section>
          <section id="spark-streaming-architecture">
            <p>
              <img width="100%" src="images/spark-streaming-architecture.png" style="border: 0">
            </p>
            <small><a href="http://spark.apache.org/docs/latest/streaming-programming-guide.html">http://spark.apache.org/docs/latest/streaming-programming-guide.html</a></small>
          </section>
        </section>

        <section id="spark-graphx">
          <h2>Spark GraphX</h2>
          <ul>
            <li>
              Distributed Graph Processing
            </li>
            <li>
              <b>Property Graph</b> on top of RDD
              <ul>
                <li>
                  A directed multigraph with properties attached to each vertex and edge
                </li>
              </ul>
            </li>
            <li>
              Graph algorithms
              <ul>
                <li>PageRank</li>
                <li>Connected Components</li>
                <li>Triangle Counting</li>
              </ul>
            </li>
          </ul>
        </section>
        <section id="tools">
          <h2>Tools</h2>
          <ul>
            <li>
              <b>spark-shell</b> - an interactive shell for Apache Spark
            </li>
            <li>
              <b>spark-submit</b> - a tool to manage Spark applications (i.e. submit, kill, status)
            </li>
            <li>
              <b>spark-sql</b> - an interactive shell for Spark SQL and Hive queries
            </li>
            <li>
              <b>web UI</b> - a web interface to monitor Spark computations
            </li>
            <li>
              <b>Scaladoc</b> - <a href="http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.package">Spark's Scala API documentation</a>
            </li>
          </ul>
        </section>

        <section id="thats-all" data-background-image="images/end.jpg">
          <!-- THAT'S IT FOLKS -->
        </section>

        <section id="questions" style="text-align: left">
          <h1>Questions?</h1>
          <p>
            <ul>
              <li>Read <a href="https://bit.ly/mastering-apache-spark">Mastering Apache Spark 2.0</a>
                <ul>
                  <li>https://bit.ly/mastering-apache-spark</li>
                </ul>
              </li>
              <li>Follow <a href="https://twitter.com/jaceklaskowski">@jaceklaskowski</a> on twitter</li>
              <li>Upvote <a href="http://stackoverflow.com/users/1305344/jacek-laskowski">my activities on StackOverflow</a></li>
              <li>Use <a href="https://github.com/jaceklaskowski">Jacek's code at GitHub</a></li>
              <li>Read <a href="https://medium.com/@jaceklaskowski">Jacek Laskowski @ Medium</a></li>
              <li>Visit <a href="https://blog.jaceklaskowski.pl">Jacek Laskowski's blog</a></li>
            </ul>
          </p>
        </section>

      </div>
    </div>

    <script src="lib/js/head.min.js"></script>
    <script src="js/reveal.js"></script>

    <script>

        // Full list of configuration options available at:
        // https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize({
            controls: true,
            progress: true,
            history: true,
            center: true,

            transition: 'slide', // none/fade/slide/convex/concave/zoom

            // Optional reveal.js plugins
            dependencies: [
                { src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
                { src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                { src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
                { src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
                { src: 'plugin/zoom-js/zoom.js', async: true },
                { src: 'plugin/notes/notes.js', async: true }
            ]
        });

    </script>
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-45999426-3', 'auto');
      ga('send', 'pageview');

    </script>
  </body>
</html>
